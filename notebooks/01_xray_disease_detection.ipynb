{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a2e97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6f3d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: d:\\HealthAI-Project\n",
      "DATA_DIR: d:\\HealthAI-Project\\datasets\\chest_xray\\chest_xray\n",
      "TRAIN_DIR: d:\\HealthAI-Project\\datasets\\chest_xray\\chest_xray\\train\n",
      "VAL_DIR: d:\\HealthAI-Project\\datasets\\chest_xray\\chest_xray\\test\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Base paths (relative to notebook location in notebooks/)\n",
    "BASE_DIR = os.path.abspath(\"..\")  # D:\\HealthAI-Project\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"datasets\", \"chest_xray\", \"chest_xray\")  # D:\\HealthAI-Project\\datasets\\chest_xray\\chest_xray\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "VAL_DIR   = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"TRAIN_DIR:\", TRAIN_DIR)\n",
    "print(\"VAL_DIR:\", VAL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf007b",
   "metadata": {},
   "source": [
    "Set Up ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e86d3651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92217ca",
   "metadata": {},
   "source": [
    "Model Skeleton (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89928772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,281\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,259,265</span> (8.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,259,265\u001b[0m (8.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,281\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = MobileNetV2(\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = False  # we will fine-tune later\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')  # binary: NORMAL vs PNEUMONIA\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858d40dc",
   "metadata": {},
   "source": [
    "Train the Pneumonia Model (Light Training Pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae394204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8086 - loss: 0.4023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 1s/step - accuracy: 0.8779 - loss: 0.2833 - val_accuracy: 0.8237 - val_loss: 0.3620\n",
      "Epoch 2/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9318 - loss: 0.1737"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 1s/step - accuracy: 0.9350 - loss: 0.1672 - val_accuracy: 0.8782 - val_loss: 0.2730\n",
      "Epoch 3/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 1s/step - accuracy: 0.9436 - loss: 0.1446 - val_accuracy: 0.8702 - val_loss: 0.2925\n",
      "Epoch 4/5\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9492 - loss: 0.1288 - val_accuracy: 0.8750 - val_loss: 0.2856\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "\n",
    "EPOCHS = 5  # start with 5\n",
    "\n",
    "checkpoint_path = os.path.join(BASE_DIR, \"models\", \"xray_disease_model.h5\")\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ade151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 784ms/step - accuracy: 0.8782 - loss: 0.2730\n",
      "Validation loss: 0.27300092577934265\n",
      "Validation accuracy: 0.8782051205635071\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(val_gen)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "print(\"Validation accuracy:\", val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07bc310",
   "metadata": {},
   "source": [
    "Get class mapping (NORMAL vs PNEUMONIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27c7cbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n",
      "{0: 'NORMAL', 1: 'PNEUMONIA'}\n"
     ]
    }
   ],
   "source": [
    "# Check class indices used by the generator\n",
    "class_indices = train_gen.class_indices\n",
    "print(class_indices)\n",
    "\n",
    "# Reverse mapping: 0 -> NORMAL, 1 -> PNEUMONIA (or as per your dataset)\n",
    "idx_to_class = {v: k for k, v in class_indices.items()}\n",
    "print(idx_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e9cb602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_to_class: {0: 'NORMAL', 1: 'PNEUMONIA'}\n",
      "Saved class mapping to: D:\\HealthAI-Project\\models\\xray_class_mapping.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"..\").resolve()  # D:\\HealthAI-Project\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "mapping_path = MODELS_DIR / \"xray_class_mapping.json\"\n",
    "\n",
    "# idx_to_class should look like {0: 'NORMAL', 1: 'PNEUMONIA'}\n",
    "print(\"idx_to_class:\", idx_to_class)\n",
    "\n",
    "# Save as JSON (keys as strings)\n",
    "with open(mapping_path, \"w\") as f:\n",
    "    json.dump({str(k): v for k, v in idx_to_class.items()}, f, indent=2)\n",
    "\n",
    "print(\"Saved class mapping to:\", mapping_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7c901",
   "metadata": {},
   "source": [
    "Helper: predict on a single X-ray image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afb3b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def predict_xray_image(img_path, model, idx_to_class, img_size=(224, 224)):\n",
    "    # Load image\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=img_size, color_mode='rgb')\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = img_array / 255.0  # same normalization as training\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # (1, H, W, 3)\n",
    "\n",
    "    # Predict\n",
    "    prob = model.predict(img_array)[0][0]  # single scalar between 0 and 1\n",
    "\n",
    "    # Threshold at 0.5\n",
    "    predicted_class_index = 1 if prob >= 0.5 else 0\n",
    "    predicted_label = idx_to_class[predicted_class_index]\n",
    "\n",
    "    # For convenience, give pneumonia probability as \"prob of class 1\"\n",
    "    pneumonia_prob = float(prob)\n",
    "    \n",
    "    return {\n",
    "        \"predicted_label\": predicted_label,\n",
    "        \"pneumonia_probability\": pneumonia_prob\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f97da93",
   "metadata": {},
   "source": [
    "Test with a real image from your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087a6fd",
   "metadata": {},
   "source": [
    "PNEUMONIA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b2c0c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample test image: d:\\HealthAI-Project\\datasets\\chest_xray\\chest_xray\\test\\PNEUMONIA\\person100_bacteria_475.jpeg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964ms/step\n",
      "{'predicted_label': 'PNEUMONIA', 'pneumonia_probability': 0.5602346658706665}\n"
     ]
    }
   ],
   "source": [
    "test_example_path = os.path.join(\n",
    "    VAL_DIR,  # this is pointing to .../chest_xray/test\n",
    "    \"PNEUMONIA\",\n",
    "    os.listdir(os.path.join(VAL_DIR, \"PNEUMONIA\"))[0]  # first pneumonia image\n",
    ")\n",
    "\n",
    "print(\"Sample test image:\", test_example_path)\n",
    "\n",
    "result = predict_xray_image(test_example_path, model, idx_to_class, IMG_SIZE)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480f2b4",
   "metadata": {},
   "source": [
    "NORMAL SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eac59070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample NORMAL image: d:\\HealthAI-Project\\datasets\\chest_xray\\chest_xray\\test\\NORMAL\\IM-0001-0001.jpeg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "{'predicted_label': 'NORMAL', 'pneumonia_probability': 0.06982818245887756}\n"
     ]
    }
   ],
   "source": [
    "test_normal_path = os.path.join(\n",
    "    VAL_DIR,\n",
    "    \"NORMAL\",\n",
    "    os.listdir(os.path.join(VAL_DIR, \"NORMAL\"))[0]\n",
    ")\n",
    "\n",
    "print(\"Sample NORMAL image:\", test_normal_path)\n",
    "\n",
    "result_normal = predict_xray_image(test_normal_path, model, idx_to_class, IMG_SIZE)\n",
    "print(result_normal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc792e",
   "metadata": {},
   "source": [
    "SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6610537",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(BASE_DIR, \"models\", \"xray_disease_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73714ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
