{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bae6930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a2e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: D:\\HealthAI-Project\n",
      "DATA_ROOT: D:\\HealthAI-Project\\datasets\\CheXpertSmall\n",
      "CHEXPERT_DIR: D:\\HealthAI-Project\\datasets\\CheXpertSmall\\CheXpert-v1.0-small\n",
      "TRAIN_CSV exists: True\n",
      "VALID_CSV exists: True\n",
      "Raw train shape: (223414, 19)\n",
      "Raw valid shape: (234, 19)\n",
      "                                                Path     Sex  Age  \\\n",
      "0  CheXpert-v1.0-small/train/patient00001/study1/...  Female   68   \n",
      "1  CheXpert-v1.0-small/train/patient00002/study2/...  Female   87   \n",
      "2  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
      "3  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
      "4  CheXpert-v1.0-small/train/patient00003/study1/...    Male   41   \n",
      "\n",
      "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
      "0         Frontal    AP         1.0                         NaN           NaN   \n",
      "1         Frontal    AP         NaN                         NaN          -1.0   \n",
      "2         Frontal    AP         NaN                         NaN           NaN   \n",
      "3         Lateral   NaN         NaN                         NaN           NaN   \n",
      "4         Frontal    AP         NaN                         NaN           NaN   \n",
      "\n",
      "   Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
      "0           NaN          NaN    NaN            NaN        NaN          NaN   \n",
      "1           1.0          NaN   -1.0           -1.0        NaN         -1.0   \n",
      "2           1.0          NaN    NaN           -1.0        NaN          NaN   \n",
      "3           1.0          NaN    NaN           -1.0        NaN          NaN   \n",
      "4           NaN          NaN    1.0            NaN        NaN          NaN   \n",
      "\n",
      "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
      "0           0.0               NaN            NaN       NaN              1.0  \n",
      "1           NaN              -1.0            NaN       1.0              NaN  \n",
      "2           NaN               NaN            NaN       1.0              NaN  \n",
      "3           NaN               NaN            NaN       1.0              NaN  \n",
      "4           0.0               NaN            NaN       NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path(\"..\").resolve()\n",
    "\n",
    "# This should point to: D:\\HealthAI-Project\\datasets\\CheXpertSmall\n",
    "DATA_ROOT = BASE_DIR / \"datasets\" / \"CheXpertSmall\"\n",
    "\n",
    "# CheXpert folder inside it\n",
    "CHEXPERT_DIR = DATA_ROOT / \"CheXpert-v1.0-small\"\n",
    "\n",
    "TRAIN_CSV = CHEXPERT_DIR / \"train.csv\"\n",
    "VALID_CSV = CHEXPERT_DIR / \"valid.csv\"\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"CHEXPERT_DIR:\", CHEXPERT_DIR)\n",
    "print(\"TRAIN_CSV exists:\", TRAIN_CSV.exists())\n",
    "print(\"VALID_CSV exists:\", VALID_CSV.exists())\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "valid_df = pd.read_csv(VALID_CSV)\n",
    "\n",
    "print(\"Raw train shape:\", train_df.shape)\n",
    "print(\"Raw valid shape:\", valid_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3099acf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    CheXpert-v1.0-small/train/patient00001/study1/...\n",
      "1    CheXpert-v1.0-small/train/patient00002/study2/...\n",
      "2    CheXpert-v1.0-small/train/patient00002/study1/...\n",
      "Name: Path, dtype: object\n",
      "Relative: CheXpert-v1.0-small/train/patient00001/study1/view1_frontal.jpg\n",
      "Full path: D:\\HealthAI-Project\\datasets\\CheXpertSmall\\CheXpert-v1.0-small\\train\\patient00001\\study1\\view1_frontal.jpg\n",
      "File exists? True\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"Path\"].head(3))\n",
    "\n",
    "first_rel = train_df[\"Path\"].iloc[0]\n",
    "full_path = DATA_ROOT / first_rel\n",
    "\n",
    "print(\"Relative:\", first_rel)\n",
    "print(\"Full path:\", full_path)\n",
    "print(\"File exists?\", full_path.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e4d25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 223414\n",
      "Valid images: 234\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>filepath</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>No Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>D:\\HealthAI-Project\\datasets\\CheXpertSmall\\Che...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>D:\\HealthAI-Project\\datasets\\CheXpertSmall\\Che...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>D:\\HealthAI-Project\\datasets\\CheXpertSmall\\Che...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>D:\\HealthAI-Project\\datasets\\CheXpertSmall\\Che...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>D:\\HealthAI-Project\\datasets\\CheXpertSmall\\Che...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  \\\n",
       "0  CheXpert-v1.0-small/train/patient00001/study1/...   \n",
       "1  CheXpert-v1.0-small/train/patient00002/study2/...   \n",
       "2  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "3  CheXpert-v1.0-small/train/patient00002/study1/...   \n",
       "4  CheXpert-v1.0-small/train/patient00003/study1/...   \n",
       "\n",
       "                                            filepath  Atelectasis  \\\n",
       "0  D:\\HealthAI-Project\\datasets\\CheXpertSmall\\Che...          0.0   \n",
       "1  D:\\HealthAI-Project\\datasets\\CheXpertSmall\\Che...          1.0   \n",
       "2  D:\\HealthAI-Project\\datasets\\CheXpertSmall\\Che...          0.0   \n",
       "3  D:\\HealthAI-Project\\datasets\\CheXpertSmall\\Che...          0.0   \n",
       "4  D:\\HealthAI-Project\\datasets\\CheXpertSmall\\Che...          0.0   \n",
       "\n",
       "   Cardiomegaly  Consolidation  Edema  Pleural Effusion  Pneumonia  \\\n",
       "0           0.0            0.0    0.0               0.0        0.0   \n",
       "1           1.0            1.0    1.0               1.0        0.0   \n",
       "2           0.0            1.0    0.0               0.0        0.0   \n",
       "3           0.0            1.0    0.0               0.0        0.0   \n",
       "4           0.0            0.0    1.0               0.0        0.0   \n",
       "\n",
       "   Pneumothorax  No Finding  \n",
       "0           0.0         1.0  \n",
       "1           0.0         0.0  \n",
       "2           0.0         0.0  \n",
       "3           0.0         0.0  \n",
       "4           0.0         0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DISEASES = [\n",
    "    \"Atelectasis\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Pleural Effusion\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",\n",
    "    \"No Finding\"\n",
    "]\n",
    "\n",
    "# Keep only needed columns\n",
    "train_df = train_df[[\"Path\"] + DISEASES].copy()\n",
    "valid_df = valid_df[[\"Path\"] + DISEASES].copy()\n",
    "\n",
    "def process_labels(df, disease_cols):\n",
    "    df = df.copy()\n",
    "    for col in disease_cols:\n",
    "        df[col] = df[col].fillna(0)\n",
    "        df[col] = df[col].replace(-1, 1)  # uncertain -> positive\n",
    "    return df\n",
    "\n",
    "train_df = process_labels(train_df, DISEASES)\n",
    "valid_df = process_labels(valid_df, DISEASES)\n",
    "\n",
    "# Build full file paths using DATA_ROOT now\n",
    "train_df[\"filepath\"] = train_df[\"Path\"].apply(lambda p: str(DATA_ROOT / p))\n",
    "valid_df[\"filepath\"] = valid_df[\"Path\"].apply(lambda p: str(DATA_ROOT / p))\n",
    "\n",
    "# Drop missing files (now should keep MANY)\n",
    "train_df = train_df[train_df[\"filepath\"].apply(os.path.exists)].reset_index(drop=True)\n",
    "valid_df = valid_df[valid_df[\"filepath\"].apply(os.path.exists)].reset_index(drop=True)\n",
    "\n",
    "print(\"Train images:\", len(train_df))\n",
    "print(\"Valid images:\", len(valid_df))\n",
    "train_df[[\"Path\", \"filepath\"] + DISEASES].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0108353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After subsample - Train: 25000 Valid: 234\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.sample(min(25000, len(train_df)), random_state=42)\n",
    "valid_df = valid_df.sample(min(5000, len(valid_df)), random_state=42)\n",
    "\n",
    "print(\"After subsample - Train:\", len(train_df), \"Valid:\", len(valid_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0826e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 validated image filenames.\n",
      "Found 234 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=DISEASES,              # list of label columns\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",            # multi-label\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=DISEASES,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"raw\",\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "239be57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,200</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │     \u001b[38;5;34m7,037,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m8,200\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,045,704</span> (26.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,045,704\u001b[0m (26.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,200</span> (32.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,200\u001b[0m (32.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> (26.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,037,504\u001b[0m (26.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "base_model = DenseNet121(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=IMG_SIZE + (3,)\n",
    ")\n",
    "\n",
    "base_model.trainable = False  # first stage: freeze base\n",
    "\n",
    "model_md = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(len(DISEASES), activation=\"sigmoid\")  # one prob per disease\n",
    "])\n",
    "\n",
    "model_md.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",  # multi-label loss\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_md.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648bec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1981 - loss: 0.5181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1452s\u001b[0m 2s/step - accuracy: 0.2054 - loss: 0.4828 - val_accuracy: 0.1068 - val_loss: 0.4171\n",
      "Epoch 2/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2122 - loss: 0.4570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1218s\u001b[0m 2s/step - accuracy: 0.2152 - loss: 0.4547 - val_accuracy: 0.2607 - val_loss: 0.4118\n",
      "Epoch 3/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2197 - loss: 0.4517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 2s/step - accuracy: 0.2190 - loss: 0.4518 - val_accuracy: 0.2906 - val_loss: 0.3939\n",
      "Epoch 4/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1213s\u001b[0m 2s/step - accuracy: 0.2213 - loss: 0.4496 - val_accuracy: 0.2906 - val_loss: 0.3982\n",
      "Epoch 5/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 2s/step - accuracy: 0.2192 - loss: 0.4496 - val_accuracy: 0.1410 - val_loss: 0.4173\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pathlib import Path\n",
    "\n",
    "MODELS_DIR = (BASE_DIR / \"models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "md_model_path = MODELS_DIR / \"xray_chexpert_multidisease_model.h5\"\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    md_model_path,\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "EPOCHS = 5  # start small – we can fine-tune more later\n",
    "\n",
    "history_md = model_md.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9975f88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.2906 - loss: 0.3939\n",
      "Multi-disease Val loss: 0.3938594460487366\n",
      "Multi-disease Val accuracy: 0.2905983030796051\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model_md.evaluate(val_gen)\n",
    "print(\"Multi-disease Val loss:\", val_loss)\n",
    "print(\"Multi-disease Val accuracy:\", val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eed66690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved labels to: D:\\HealthAI-Project\\models\\xray_chexpert_labels.json\n",
      "Saved model to: D:\\HealthAI-Project\\models\\xray_chexpert_multidisease_model.h5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "labels_path = MODELS_DIR / \"xray_chexpert_labels.json\"\n",
    "\n",
    "with open(labels_path, \"w\") as f:\n",
    "    json.dump(DISEASES, f, indent=2)\n",
    "\n",
    "print(\"Saved labels to:\", labels_path)\n",
    "print(\"Saved model to:\", md_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2d78beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "def predict_chexpert_image(img_path, model, diseases, img_size=(224, 224)):\n",
    "    img = load_img(img_path, target_size=img_size, color_mode=\"rgb\")\n",
    "    arr = img_to_array(img) / 255.0\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "\n",
    "    probs = model.predict(arr)[0]  # shape: (len(diseases),)\n",
    "\n",
    "    return {diseases[i]: float(probs[i]) for i in range(len(diseases))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7899130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image: D:\\HealthAI-Project\\datasets\\CheXpertSmall\\CheXpert-v1.0-small\\valid\\patient64592\\study1\\view1_frontal.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Atelectasis': 0.3581162393093109,\n",
       " 'Cardiomegaly': 0.12076950818300247,\n",
       " 'Consolidation': 0.12704865634441376,\n",
       " 'Edema': 0.21756716072559357,\n",
       " 'Pleural Effusion': 0.34631186723709106,\n",
       " 'Pneumonia': 0.028416648507118225,\n",
       " 'Pneumothorax': 0.04238026589155197,\n",
       " 'No Finding': 0.07330987602472305}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_path = valid_df[\"filepath\"].iloc[0]\n",
    "print(\"Sample image:\", sample_path)\n",
    "\n",
    "preds = predict_chexpert_image(sample_path, model_md, DISEASES, IMG_SIZE)\n",
    "preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52fb8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
